{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blue-create/langlens/blob/main/to_publish/extract_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BbjDacn_sZj"
      },
      "source": [
        "# Unzippen und Extrahieren von Daten\n",
        "In diesem Notebook werden die Zip-Dateien extrahiert und gelesen und nach einem ersten Filter nach Land und Inhalt gespeichert.\n",
        "\n",
        "Schritte:\n",
        "1. Unzippen der XMLs in allen Ordnern\n",
        "2. Konvertieren der XMLs zu CSV, mit erstem Filter:\n",
        "  - nur deutsche Zeitungen, in deutscher Sprache\n",
        "  - nur Artikel über häusliche Gewalt (nach Keyword-Search)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol8OTQTrLRVa"
      },
      "source": [
        "### Imports, Konstanten, Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q54rsCBHLa-C"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "from tqdm import tqdm\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wm67xGU2Lg-V"
      },
      "outputs": [],
      "source": [
        "# Definieren der Paths\n",
        "RAW=\"0_Raw\"\n",
        "UNZIPPED=\"1_Unzipped\"\n",
        "FILTERED=\"2_Filtered/230818\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55fsThdDRuDs"
      },
      "outputs": [],
      "source": [
        "# Verbinden mit GDrive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqh8TaqvAayx"
      },
      "source": [
        "## Unzippen der Dateien\n",
        "- XMLs in Ordnern werden extrahiert und gespeichert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDLAdk9nWvNY",
        "outputId": "79e21f58-40a5-4c8b-dbea-898ee56ce430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Anzahl der Zeitungs-Ordner:  257\n"
          ]
        }
      ],
      "source": [
        "#Überprüfen der Anzahl der Dateien\n",
        "num_files = len(os.listdir(RAW))\n",
        "print(\"Anzahl der Zeitungs-Ordner: \", num_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6QhI0PoVFUk"
      },
      "outputs": [],
      "source": [
        "## Extrahieren aller XMLs in jedem Zeitungs-Ordner\n",
        "for filename in os.listdir(RAW)\n",
        "    if filename.endswith(\".zip\"):\n",
        "        if zipfile.is_zipfile(os.path.join(RAW, filename)):\n",
        "            with zipfile.ZipFile(os.path.join(RAW, filename), \"r\") as zip_ref:\n",
        "                zip_ref.extractall(UNZIPPED)\n",
        "        else:\n",
        "            print(f\"Datei {filename} ist keine Zip-Datei und wird nicht extrahiert.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LS_uVeg2pl1G"
      },
      "outputs": [],
      "source": [
        "## Überprüfen ob alle Zip-Dateien extrahiert wurden\n",
        "for filename in os.listdir(RAW):\n",
        "    if filename.endswith(\".zip\"):\n",
        "        name = filename.split(\".\")[0]\n",
        "        for xml_filename in os.listdir(UNZIPPED):\n",
        "            if xml_filename.startswith(name) and xml_filename.endswith(\".xml\"):\n",
        "                break\n",
        "        else:\n",
        "            print(f\"Es gibt keine XMLs-Datei für {filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWH914I31Vhg"
      },
      "source": [
        "## Lesen der XMLs und erstes Filtern der Artikel und Titel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKUw_Q2hNFkm"
      },
      "source": [
        "### Dictionarys zum Filtern\n",
        "- diese Keyword-Liste wurde in einem iterativen Prozess erstellt um alle Artikel zum Thema Partnerschaftsgewalt zu erhalten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGsImkzwk_bF"
      },
      "outputs": [],
      "source": [
        "# Definieren der Schlagworte zur ersten Keyword-Search der Artikel\n",
        "comb=[\n",
        "    \"häuslicher? gewalt\",\n",
        "    \"ehedrama\",\n",
        "    \"familienstreit und partner(in)?\",\n",
        "    \"gewalttätige[rn]? (ex-)?partner(in)?\",\n",
        "    \"gewalttätige[rn]? Ehe(partner|mann|frau)?(in)?\",\n",
        "    \"partnerschaftsgewalt\",\n",
        "    \"femizid\",\n",
        "    \"gewalt in (der )?(\\(ex-\\))?(ex)?partnerschaft(en)?\",\n",
        "    \"beziehungsgewalt\",\n",
        "    \"beziehungstat\",\n",
        "    \"gewalttätige[rn]? (ex(-)?)?freund(in)?\",\n",
        "    \"beziehungsdrama\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF1yF5Tr3ev0"
      },
      "outputs": [],
      "source": [
        "# Definieren der Schlagworte dich nicht in relevanten Artikel auftauchen\n",
        "exclude_titles=[\n",
        "  #LESERBRIEFE\n",
        "  \"lesermeinung\",\n",
        "  \"leserbrief\",\n",
        "  \"LIEBE LESERIN, LIEBER LESER\",\n",
        "  #ANDERE KATEGORIEN\n",
        "  \"Corona-Ticker\"\n",
        "  \"EM-Tabelle\",\n",
        "  \"finanztrends\",\n",
        "  \"News Ticker\",\n",
        "  \"TV-Programm\",\n",
        "  \"TV-\"\n",
        "  \"Kriminalhörspiel\",\n",
        "  \"TV-Tipp des Tages\",\n",
        "  \"thriller\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbSGEA1tG5RR"
      },
      "source": [
        "### Methoden\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7NRwFGc6Bsh"
      },
      "outputs": [],
      "source": [
        "# Funktion zum Lesen von XML-Dateien und speichern aller Artikel in einer Liste\n",
        "def parse_xml_file(xml_file):\n",
        "  \"\"\" Funktion, die alle XMLs einer Zeitung liest und die Artikel mit Metadaten extrahiert\n",
        "  Parameters:\n",
        "    - prefix (str): Kürzel der Zeitung\n",
        "  Returns:\n",
        "    - json: Kombinierte Liste der Artikel\n",
        "  \"\"\"\n",
        "  tree = ET.parse(os.path.join(UNZIPPED, xml_file))\n",
        "  root = tree.getroot()\n",
        "  json_file = []\n",
        "  for artikel in root.findall('artikel'):\n",
        "    artikel_id = artikel.find('metadaten/artikel-id')\n",
        "    artikel_id = artikel_id.text if artikel_id is not None else None\n",
        "    name = artikel.find('metadaten/quelle/name').text\n",
        "    jahrgang = artikel.find('metadaten/quelle/jahrgang')\n",
        "    jahrgang = jahrgang.text if jahrgang is not None else None\n",
        "    autor = artikel.find('metadaten/autor/autor-name')\n",
        "    autor = autor.text if autor is not None else None\n",
        "    datum = artikel.find('metadaten/quelle/datum')\n",
        "    datum = datum.text if datum is not None else None\n",
        "    ressort_elem = artikel.find('inhalt/titel-liste/ressort')\n",
        "    ressort = ressort_elem.text if ressort_elem is not None else None\n",
        "    titel_elem = artikel.find('inhalt/titel-liste/titel')\n",
        "    titel = titel_elem.text if titel_elem is not None else None\n",
        "\n",
        "    untertitel_elem = artikel.find('inhalt/titel-liste/untertitel')\n",
        "    untertitel = untertitel_elem.text if untertitel_elem is not None else None\n",
        "\n",
        "    text = []\n",
        "    text_elem = artikel.find('inhalt/text')\n",
        "    try:\n",
        "        p_elems = text_elem.findall('p')\n",
        "        for p_elem in p_elems:\n",
        "            p_text = p_elem.text\n",
        "            if p_text is not None:\n",
        "              text.append(p_text)\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "    temp_dict = {}\n",
        "    temp_dict['artikel_id'] = str(artikel_id)\n",
        "    temp_dict['name'] = name\n",
        "    temp_dict['jahrgang'] = jahrgang\n",
        "    temp_dict['datum'] = datum\n",
        "    temp_dict['ressort'] = ressort\n",
        "    temp_dict['titel'] = titel\n",
        "    temp_dict['untertitel'] = untertitel\n",
        "    temp_dict['text'] = text\n",
        "    temp_dict['autor'] = autor\n",
        "\n",
        "    json_file.append(temp_dict)\n",
        "  return json_file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugnHlDF1Z0VO"
      },
      "outputs": [],
      "source": [
        "#Funktion zum Filtern von Artikeln während des Extrahierens\n",
        "def filter_text_by_list(text, list_match):\n",
        "  \"\"\"  Funktion um zu vergleichen ob minestens ein Wort in einer Liste von Wörtern in einem Text vorkommt und keines einer zweiten Liste von Wörtern\n",
        "  Parameters:\n",
        "    - text (str or list of str): Text der überprüft wird\n",
        "    - list_match (list of str): Liste von Wörtern, nach denen gesucht wird\n",
        "    - list_no_match (list of str): Liste von Wörtern, die nicht vorkommen dürfen\n",
        "  Returns:\n",
        "    - boolean:\n",
        "      - True: wenn min. eines der ersten Liste, und keines der zweiten Liste von Wörtern im Text vorkommt\n",
        "      - False: wenn keins der ersten oder min ein Wort der zweiten Wörterliste im Text vorkommen\n",
        "  \"\"\"\n",
        "  text=\" \".join(text).lower()\n",
        "\n",
        "  for comb in list_match:\n",
        "    if all(occurs(word,text)  for word in comb.split(\" und \")):\n",
        "      return True\n",
        "  return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJBbe6OeW5SQ"
      },
      "outputs": [],
      "source": [
        "# Funktion zum überprüfen ob Datei schon exportiert wurde\n",
        "def check_if_exported(prefix, filtered_path):\n",
        "  \"\"\" Funktion zum Überprüfen, ob die Dateien für eine Zeitung schon exportiert wurden\n",
        "  Parameters:\n",
        "    - prefix (str): Kürzel der Zeitung\n",
        "    - filtered_path: Path, in dem gesucht wird\n",
        "  Returns:\n",
        "    - boolean: True, wenn die Dateien für die Zeitung schon exportiert wurde, sonst False\n",
        "  \"\"\"\n",
        "  filtered=os.listdir(filtered_path)\n",
        "  filtered = [file.split(\".\")[0]for file in filtered if file.endswith(\".csv\")]\n",
        "  if prefix in filtered:\n",
        "    print(f\"{prefix} csv already exported\")\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5cECPQsPLLn"
      },
      "outputs": [],
      "source": [
        "# Funktion zum prüfen ob ein Schlagwort in einem Text vorkommt\n",
        "def occurs(word, text):\n",
        "  \"\"\" Funktion zum Überprüfen, ob Wort in Text auftaucht\n",
        "  Parameters:\n",
        "    - word (str): Wort nach dem gesucht wird\n",
        "    - text (str): Text in dem gesucht wird\n",
        "  Returns:\n",
        "    - boolean: True, wenn das Wort in dem Text gefunden wird, sonst False\n",
        "  \"\"\"\n",
        "  if len(re.findall(word,text))>0:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EnfcxByqmjR"
      },
      "outputs": [],
      "source": [
        "# Funktion zum Filtern von Artikel basieren auf dem Titel\n",
        "def filter_title(title):\n",
        "  \"\"\" Funktion zum Filtern eines Artikels nach Titel (mit Liste: exclude_titles)\n",
        "  Parameters:\n",
        "    - title (str): Titel der überprüft werden soll\n",
        "  Returns:\n",
        "    - boolean: True, wenn\n",
        "        - kein Titel\n",
        "        - der Titel ist nicht in der Liste exclude_titles\n",
        "  \"\"\"\n",
        "  if type(title)!=str:\n",
        "    return True\n",
        "  for ex in exclude_titles:\n",
        "    if ex.lower() in title.lower():\n",
        "      return False\n",
        "  return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptRgTeZL_4vm"
      },
      "source": [
        "### Filter nach Land\n",
        "Alle nicht deutschen und nicht-deutschsprachigen Zeitungen werden ausgeschlossen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCcdaiOWE7FN"
      },
      "outputs": [],
      "source": [
        "# Erstellen einer Liste der Kürzel der relevanten Zeitungen\n",
        "all_prefixes= sorted([i.split(\".\")[0] for i in os.listdir(RAW)])\n",
        "prefixes_to_exclude=['AGZ', \"ANEW\", \"APZT\",\"AWP\", \"AWPO\", \"AWPU\", \"BAZ\", \"BERN\", \"BEOB\", \"BLI\", \"BUND\", \"BWAI\", \"DIEW\", \"DOL\", \"ELNA\",\"HZ\", \"HZO\", \"KLEI\", \"KRON\", \"KUR\", \"LUXT\", \"LZLZ\", \"NECH\",\"NLZ\", \"NVB\",\"NVT\",\"NZZ\", \"NZZS\", \"OOEN\", \"PBN\", \"PRE\", \"PROF\", \"RVZ\",\"SBLI\",\"SN\",\"STA\",\"STG\",\"TAG\",\"TAS\",\"THTA\",\"TITA\",\"VN\",\"WEWO\",\"WZ\",\"ZSAS\", \"NBPC\",\"NBPC_part1\",\"NBPC_part2\",\"NBPC_part3\",\"NBPC_part4\",\"FALT\",\"RTAL\"]\n",
        "prefixes= sorted([i.split(\".\")[0] for i in os.listdir(RAW)])\n",
        "prefixes=list(set(prefixes) - set(prefixes_to_exclude))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsaZupmYAHl9"
      },
      "source": [
        "### Filtern nach Key-Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "my9Pn_kC66bV"
      },
      "outputs": [],
      "source": [
        "# Für alle relevanten Zeitungen:\n",
        "# XML lesen, nach Titel und Artikel Text Filtern und resultierende Artikel als CSV speichern\n",
        "\n",
        "for prefix in tqdm(prefixes):\n",
        "  if not check_if_exported(prefix, FILTERED):\n",
        "    xmls=[i for i in os.listdir(UNZIPPED) if i.startswith(prefix+\"_\")]\n",
        "    DV_art=[]\n",
        "    for xml in xmls:\n",
        "      parsed_xml=parse_xml_file(xml)\n",
        "      for art in parsed_xml:\n",
        "        if filter_title(art[\"titel\"] ):\n",
        "          if filter_text_by_list(art[\"text\"],comb):\n",
        "              DV_art.append(art)\n",
        "    DV_art=pd.DataFrame(DV_art)\n",
        "    DV_art=DV_art.drop_duplicates(\"text\")\n",
        "    DV_art.to_csv(FILTERED+\"/\"+prefix+\".csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RKUw_Q2hNFkm"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
